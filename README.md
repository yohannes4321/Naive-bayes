Naive Bayes: A probabilistic classifier based on Bayes' theorem.

Logistic Regression: A linear model for binary classification.

The performance of both models is compared using metrics like accuracy, precision, recall, and F1-score.


Uses the MultinomialNB classifier , which is suitable for discrete data like word counts. normal Gaussian method for continous data 

Trained on the feature vectors generated by CountVectorizer.

Naive Bayes:

Slightly outperforms Logistic Regression in terms of accuracy, precision, and F1-score.

Computationally efficient and works well with small datasets.

Assumes independence between features, which may not always hold true.

Logistic Regression:

Performs almost as well as Naive Bayes but with slightly lower metrics.

More flexible and can capture relationships between features better.

Requires more computational resources.

Which Model to Choose?

Use Naive Bayes for interpretability and computational efficiency.

Use Logistic Regression for more complex datasets or when feature relationships are important.